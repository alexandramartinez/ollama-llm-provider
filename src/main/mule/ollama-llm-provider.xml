<?xml version="1.0" encoding="UTF-8"?>
<mule xmlns="http://www.mulesoft.org/schema/mule/core" xmlns:apikit="http://www.mulesoft.org/schema/mule/mule-apikit" xmlns:doc="http://www.mulesoft.org/schema/mule/documentation" xmlns:ee="http://www.mulesoft.org/schema/mule/ee/core" xmlns:http="http://www.mulesoft.org/schema/mule/http" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ms-aichain="http://www.mulesoft.org/schema/mule/ms-aichain" xsi:schemaLocation="http://www.mulesoft.org/schema/mule/core http://www.mulesoft.org/schema/mule/core/current/mule.xsd http://www.mulesoft.org/schema/mule/http http://www.mulesoft.org/schema/mule/http/current/mule-http.xsd http://www.mulesoft.org/schema/mule/mule-apikit http://www.mulesoft.org/schema/mule/mule-apikit/current/mule-apikit.xsd http://www.mulesoft.org/schema/mule/ee/core http://www.mulesoft.org/schema/mule/ee/core/current/mule-ee.xsd 
	http://www.mulesoft.org/schema/mule/ms-aichain http://www.mulesoft.org/schema/mule/ms-aichain/current/mule-ms-aichain.xsd">
    <http:listener-config name="llm-open-connector-httpListenerConfig">
        <http:listener-connection host="0.0.0.0" port="8081" />
    </http:listener-config>
    <apikit:config name="llm-open-connector-config" api="resource::your-org-id:llm-open-connector:1.0.0:oas:zip:llm-open-connector.yaml" outboundHeadersMapName="outboundHeaders" httpStatusVarName="httpStatus" />
    <ms-aichain:config configType="Configuration Json" filePath='#[(mule.home default "") ++ "/apps/" ++ (app.name default "") ++ "/llm-config.json"]' llmType="OLLAMA" modelName="#[vars.inputPayload.model default 'llama3']" name="MAC_Config" temperature="#[vars.inputPayload.temperature default 1]" maxTokens="#[vars.inputPayload.max_tokens default 500]"></ms-aichain:config>
    <flow name="llm-open-connector-main">
        <http:listener config-ref="llm-open-connector-httpListenerConfig" path="/api/*">
            <http:response statusCode="#[vars.httpStatus default 200]">
                <http:headers>#[vars.outboundHeaders default {}]</http:headers>
            </http:response>
            <http:error-response statusCode="#[vars.httpStatus default 500]">
                <http:body>#[payload]</http:body>
                <http:headers>#[vars.outboundHeaders default {}]</http:headers>
            </http:error-response>
        </http:listener>
        <apikit:router config-ref="llm-open-connector-config" />
        <error-handler>
            <on-error-propagate type="APIKIT:BAD_REQUEST">
                <ee:transform doc:name="Transform Message">
                    <ee:message>
                        <ee:set-payload>
                            <![CDATA[%dw 2.0
output application/json
---
{message: "Bad request"}]]>
                        </ee:set-payload>
                    </ee:message>
                    <ee:variables>
                        <ee:set-variable variableName="httpStatus">400</ee:set-variable>
                    </ee:variables>
                </ee:transform>
            </on-error-propagate>
            <on-error-propagate type="APIKIT:NOT_FOUND">
                <ee:transform doc:name="Transform Message">
                    <ee:message>
                        <ee:set-payload>
                            <![CDATA[%dw 2.0
output application/json
---
{message: "Resource not found"}]]>
                        </ee:set-payload>
                    </ee:message>
                    <ee:variables>
                        <ee:set-variable variableName="httpStatus">404</ee:set-variable>
                    </ee:variables>
                </ee:transform>
            </on-error-propagate>
            <on-error-propagate type="APIKIT:METHOD_NOT_ALLOWED">
                <ee:transform doc:name="Transform Message">
                    <ee:message>
                        <ee:set-payload>
                            <![CDATA[%dw 2.0
output application/json
---
{message: "Method not allowed"}]]>
                        </ee:set-payload>
                    </ee:message>
                    <ee:variables>
                        <ee:set-variable variableName="httpStatus">405</ee:set-variable>
                    </ee:variables>
                </ee:transform>
            </on-error-propagate>
            <on-error-propagate type="APIKIT:NOT_ACCEPTABLE">
                <ee:transform doc:name="Transform Message">
                    <ee:message>
                        <ee:set-payload>
                            <![CDATA[%dw 2.0
output application/json
---
{message: "Not acceptable"}]]>
                        </ee:set-payload>
                    </ee:message>
                    <ee:variables>
                        <ee:set-variable variableName="httpStatus">406</ee:set-variable>
                    </ee:variables>
                </ee:transform>
            </on-error-propagate>
            <on-error-propagate type="APIKIT:UNSUPPORTED_MEDIA_TYPE">
                <ee:transform doc:name="Transform Message">
                    <ee:message>
                        <ee:set-payload>
                            <![CDATA[%dw 2.0
output application/json
---
{message: "Unsupported media type"}]]>
                        </ee:set-payload>
                    </ee:message>
                    <ee:variables>
                        <ee:set-variable variableName="httpStatus">415</ee:set-variable>
                    </ee:variables>
                </ee:transform>
            </on-error-propagate>
            <on-error-propagate type="APIKIT:NOT_IMPLEMENTED">
                <ee:transform doc:name="Transform Message">
                    <ee:message>
                        <ee:set-payload>
                            <![CDATA[%dw 2.0
output application/json
---
{message: "Not Implemented"}]]>
                        </ee:set-payload>
                    </ee:message>
                    <ee:variables>
                        <ee:set-variable variableName="httpStatus">501</ee:set-variable>
                    </ee:variables>
                </ee:transform>
            </on-error-propagate>
        </error-handler>
    </flow>
    <flow name="llm-open-connector-console">
        <http:listener config-ref="llm-open-connector-httpListenerConfig" path="/console/*">
            <http:response statusCode="#[vars.httpStatus default 200]">
                <http:headers>#[vars.outboundHeaders default {}]</http:headers>
            </http:response>
            <http:error-response statusCode="#[vars.httpStatus default 500]">
                <http:body>#[payload]</http:body>
                <http:headers>#[vars.outboundHeaders default {}]</http:headers>
            </http:error-response>
        </http:listener>
        <apikit:console config-ref="llm-open-connector-config" />
        <error-handler>
            <on-error-propagate type="APIKIT:NOT_FOUND">
                <ee:transform doc:name="Transform Message">
                    <ee:message>
                        <ee:set-payload>
                            <![CDATA[%dw 2.0
output application/json
---
{message: "Resource not found"}]]>
                        </ee:set-payload>
                    </ee:message>
                    <ee:variables>
                        <ee:set-variable variableName="httpStatus">404</ee:set-variable>
                    </ee:variables>
                </ee:transform>
            </on-error-propagate>
        </error-handler>
    </flow>
    <flow name="post:\chat\completions:application\json:llm-open-connector-config">
        <logger doc:name="Logger" doc:id="ezzhif" message="#[payload]" />
        <ee:transform doc:name="Transform" doc:id="dstcls">
            <ee:message>
                <ee:set-payload><![CDATA[payload.messages[0].content]]></ee:set-payload>
            </ee:message>
            <ee:variables>
                <ee:set-variable variableName="inputPayload">
                    <![CDATA[payload]]>
                </ee:set-variable>
            </ee:variables>
        </ee:transform>
        <ms-aichain:chat-answer-prompt config-ref="MAC_Config" doc:id="mmoptd" doc:name="Chat answer prompt" />
        <ee:transform doc:name="Transform" doc:id="czdqgi">
            <ee:message>
                <ee:set-payload>
                    <![CDATA[output application/json
---
{
    id: uuid( ),
    choices: [
        {
            finish_reason: "stop",
            index: 0,
            message: {
                content: payload.response default "",
                role: "assistant"
            }
        }
    ],
    created: now() as Number,
    model: vars.inputPayload.model default "",
    object: "chat.completion",
    usage: {
        completion_tokens: (attributes.tokenUsage.outputCount default 0) as Number,
        prompt_tokens: (attributes.tokenUsage.inputCount default 0) as Number,
        total_tokens: (attributes.tokenUsage.totalCount default 0) as Number
    }
}]]>
                </ee:set-payload>
            </ee:message>
        </ee:transform>
        <logger doc:name="Logger" doc:id="rzhuiw" message="#[payload]" />
    </flow>
</mule>